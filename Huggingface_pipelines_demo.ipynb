{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Huggingface_pipelines_demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOxeSVFmPmf5dh966Xw4CVL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/Huggingface_pipelines_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEA3BJck0yvw",
        "colab_type": "text"
      },
      "source": [
        "# Demo of [Huggingface Transformers](https://github.com/huggingface/transformers) pipelines\n",
        "\n",
        "New in version `v2.3`: `Pipeline` are high-level objects which automatically handle tokenization, running your data through a transformers model\n",
        "and outputting the result in a structured object.\n",
        "\n",
        "You can create `Pipeline` objects for the following down-stream tasks:\n",
        "\n",
        " - `feature-extraction`: Generates a tensor representation for the input sequence\n",
        " - `ner`: Generates named entity mapping for each word in the input sequence.\n",
        " - `sentiment-analysis`: Gives the polarity (positive / negative) of the whole input sequence.\n",
        " - `question-answering`: Provided some context and a question refering to the context, it will extract the answer to the question\n",
        " in the context.\n",
        "\n",
        " > Colab creator: [Manuel Romero](https://twitter.com/mrm8488)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YTuVJUv1_tM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bd650f2c-5d9e-4996-b43f-d0eae4257a15"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvF2APhH1Zii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "outputId": "923b5c04-c289-4834-fa11-7a2096eb5516"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: numpy in /tensorflow-2.1.0/python3.6 (from transformers) (1.18.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: requests in /tensorflow-2.1.0/python3.6 (from transformers) (2.22.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.10.47)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (1.25.7)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /tensorflow-2.1.0/python3.6 (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.47 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.13.47)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: six in /tensorflow-2.1.0/python3.6 (from sacremoses->transformers) (1.14.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.47->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mZJLpVC1N_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvXGY6iz5kHJ",
        "colab_type": "text"
      },
      "source": [
        "## 1. Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnJmxKJj5LVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "62f47868-1af5-4501-9c96-fd2df48727aa"
      },
      "source": [
        "nlp_sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
        "text_sentiment = \"We are very happy to include pipeline into the transformers repository\"\n",
        "nlp_sentiment_analysis(text_sentiment)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.99687505}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAoHGP8F5oPg",
        "colab_type": "text"
      },
      "source": [
        "## 2. Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laT8e0BT5xkT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "927a4f0a-d1b1-42ea-81e1-cf545311a18c"
      },
      "source": [
        "nlp_qa = pipeline(\"question-answering\")\n",
        "context = \"Pipeline have been included in the huggingface/transformers repository\"\n",
        "question = \"What is the name of the repository?\"\n",
        "nlp_qa({\n",
        "    'question': question,\n",
        "    'context': context\n",
        "})"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting examples to features: 100%|██████████| 1/1 [00:00<00:00, 117.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'huggingface/transformers',\n",
              " 'end': 59,\n",
              " 'score': 0.2875603414669605,\n",
              " 'start': 35}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FStvE_ls6V51",
        "colab_type": "text"
      },
      "source": [
        "## 3. NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74R1YM5x6nnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_ner = pipeline(\"ner\")\n",
        "text_ner = \"We are very happy to include pipeline into the transformers repository\"\n",
        "nlp_ner(text_ner)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wXZbCq162ka",
        "colab_type": "text"
      },
      "source": [
        "## 4. Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZdThaEG6-2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_fe = pipeline(\"feature-extraction\")\n",
        "text_fe = \"We are very happy to include pipeline into the transformers repository\"\n",
        "nlp_fe(text_fe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM22GQsb7Nrz",
        "colab_type": "text"
      },
      "source": [
        "## 5. Bonus Forms (sentiment-analysis, ner, feature-extraction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiJ0-z8B7ROd",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title Choose a pipeline and write a text { run: \"auto\" }\n",
        "task = 'ner' #@param [\"sentiment-analysis\", \"ner\", \"feature-extraction\"]\n",
        "text = 'We are very happy to include pipeline into the transformers repository.' #@param {type:\"string\"}\n",
        "nlp = pipeline(task)\n",
        "nlp(text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfI-QbZh7yCR",
        "colab_type": "text"
      },
      "source": [
        "## question-answering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn2J9RXq73-E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "2d1e58ca-1149-455f-94b9-ef0656c0036c"
      },
      "source": [
        "#@title Write a context and a question { run: \"auto\" }\n",
        "context = 'Pipeline have been included in the huggingface/transformers repository' #@param {type:\"string\"}\n",
        "question = 'What is the name of the repository?' #@param {type:\"string\"}\n",
        "nlp_qa = pipeline(\"question-answering\")\n",
        "nlp_qa({\n",
        "    'question': question,\n",
        "    'context': context\n",
        "})"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting examples to features: 100%|██████████| 1/1 [00:00<00:00, 333.62it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'huggingface/transformers',\n",
              " 'end': 59,\n",
              " 'score': 0.2875603414669605,\n",
              " 'start': 35}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    }
  ]
}