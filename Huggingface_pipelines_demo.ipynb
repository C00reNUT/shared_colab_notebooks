{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Huggingface_pipelines_demo.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO2A1mlgZxYqDLu2yh7MtLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/Huggingface_pipelines_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BEA3BJck0yvw",
        "colab_type": "text"
      },
      "source": [
        "# Demo of [Huggingface Transformers](https://github.com/huggingface/transformers) pipelines\n",
        "\n",
        "New in version `v2.3`: `Pipeline` are high-level objects which automatically handle tokenization, running your data through a transformers model\n",
        "and outputting the result in a structured object.\n",
        "\n",
        "You can create `Pipeline` objects for the following down-stream tasks:\n",
        "\n",
        " - `feature-extraction`: Generates a tensor representation for the input sequence\n",
        " - `ner`: Generates named entity mapping for each word in the input sequence.\n",
        " - `sentiment-analysis`: Gives the polarity (positive / negative) of the whole input sequence.\n",
        " - `question-answering`: Provided some context and a question refering to the context, it will extract the answer to the question\n",
        " in the context.\n",
        "\n",
        " > Colab creator: [Manuel Romero](https://twitter.com/mrm8488)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YTuVJUv1_tM",
        "colab_type": "code",
        "outputId": "396d7990-53cd-4a30-9763-7f2b3f10f799",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KvF2APhH1Zii",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mZJLpVC1N_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvXGY6iz5kHJ",
        "colab_type": "text"
      },
      "source": [
        "## 1. Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnJmxKJj5LVW",
        "colab_type": "code",
        "outputId": "74d0bb53-dbb9-48ef-8d78-b24f2f39bdf5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "nlp_sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
        "text_sentiment = \"We are very happy to include pipeline into the transformers repository\"\n",
        "nlp_sentiment_analysis(text_sentiment)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.99687505}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAoHGP8F5oPg",
        "colab_type": "text"
      },
      "source": [
        "## 2. Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "laT8e0BT5xkT",
        "colab_type": "code",
        "outputId": "c2b0aebe-2f4d-4861-b21c-eb2e6828c35b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "nlp_qa = pipeline(\"question-answering\")\n",
        "context = \"Pipeline have been included in the huggingface/transformers repository\"\n",
        "question = \"What is the name of the repository?\"\n",
        "nlp_qa({\n",
        "    'question': question,\n",
        "    'context': context\n",
        "})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting examples to features: 100%|██████████| 1/1 [00:00<00:00, 181.11it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'huggingface/transformers',\n",
              " 'end': 59,\n",
              " 'score': 0.2875603414669605,\n",
              " 'start': 35}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FStvE_ls6V51",
        "colab_type": "text"
      },
      "source": [
        "## 3. NER\n",
        "Not working at 01/31/2020"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74R1YM5x6nnQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_ner = pipeline(\"ner\")\n",
        "text_ner = \"We are very happy to include pipeline into the transformers repository\"\n",
        "nlp_ner(text_ner)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wXZbCq162ka",
        "colab_type": "text"
      },
      "source": [
        "## 4. Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZdThaEG6-2s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_fe = pipeline(\"feature-extraction\")\n",
        "text_fe = \"We are very happy to include pipeline into the transformers repository\"\n",
        "nlp_fe(text_fe)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM22GQsb7Nrz",
        "colab_type": "text"
      },
      "source": [
        "## 5. Bonus Forms (sentiment-analysis, ner, feature-extraction)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiJ0-z8B7ROd",
        "colab_type": "code",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e6e9c82b-e6c5-4f31-f488-4fd4d5c1a2fb"
      },
      "source": [
        "#@title Choose a pipeline and write a text { run: \"auto\" }\n",
        "task = 'sentiment-analysis' #@param [\"sentiment-analysis\", \"ner\", \"feature-extraction\"]\n",
        "text = 'We are very happy to include pipeline into the transformers repository.' #@param {type:\"string\"}\n",
        "nlp = pipeline(task)\n",
        "nlp(text)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.99781936}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfI-QbZh7yCR",
        "colab_type": "text"
      },
      "source": [
        "## question-answering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn2J9RXq73-E",
        "colab_type": "code",
        "outputId": "09453653-bef2-430a-f31f-c7743c624929",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "#@title Write a context and a question { run: \"auto\" }\n",
        "context = 'Bitcoin[a] (\\u20BF) is a cryptocurrency. It is a decentralized digital currency without a central bank or single administrator that can be sent from user to user on the peer-to-peer bitcoin network without the need for intermediaries.[8]  Transactions are verified by network nodes through cryptography and recorded in a public distributed ledger called a blockchain. Bitcoin was invented in 2008 by an unknown person or group of people using the name Satoshi Nakamoto[15] and started in 2009[16] when its source code was released as open-source software.[7]:ch. 1 Bitcoins are created as a reward for a process known as mining. They can be exchanged for other currencies, products, and services.[17] Research produced by University of Cambridge estimates that in 2017, there were 2.9 to 5.8 million unique users using a cryptocurrency wallet, most of them using bitcoin.[18]  Bitcoin has been criticized for its use in illegal transactions, its high electricity consumption, price volatility, and thefts from exchanges. Some economists, including several Nobel laureates, have characterized it as a speculative bubble. Bitcoin has also been used as an investment, although several regulatory agencies have issued investor alerts about bitcoin.[19][20]' #@param {type:\"string\"}\n",
        "question = 'How are Bitcoins created?' #@param {type:\"string\"}\n",
        "nlp_qa = pipeline(\"question-answering\")\n",
        "nlp_qa({\n",
        "    'question': question,\n",
        "    'context': context\n",
        "})"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting examples to features: 100%|██████████| 1/1 [00:00<00:00, 110.54it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'as a reward for a process known as mining.',\n",
              " 'end': 623,\n",
              " 'score': 0.5793336972202461,\n",
              " 'start': 581}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hK7kGyrd1pWG",
        "colab_type": "text"
      },
      "source": [
        "## 6. BONUS (II) Mask filling with **umBERTo**, an Italian <img alt=\"🇮🇹\" draggable=\"false\" src=\"https://abs-0.twimg.com/emoji/v2/svg/1f1ee-1f1f9.svg\" width=\"32\" height=\"32\"> Language Model trained with Whole Word Masking.\n",
        "\n",
        "(Not working yet at Not working at 01/31/2020. Source code: https://github.com/musixmatchresearch/umberto)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANlnLMjy3b5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp_fill_mask_ita = pipeline(\n",
        "\t\"fill-mask\",\n",
        "\tmodel=\"Musixmatch/umberto-commoncrawl-cased-v1\",\n",
        "\ttokenizer=\"Musixmatch/umberto-commoncrawl-cased-v1\"\n",
        ")\n",
        "\n",
        "nlp_fill_mask_ita(\"Umberto Eco è <mask> un grande scrittore\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}