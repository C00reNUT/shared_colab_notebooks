{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ry_mrm8488_xquad_finetuned_uncased_model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAxZCCnm3FpkBseQnoXx6A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrm8488/shared_colab_notebooks/blob/master/ry_mrm8488_xquad_finetuned_uncased_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTFfiD2JdN5B",
        "colab_type": "text"
      },
      "source": [
        "# Colab to try the model [mrm8488/bert-multi-uncased-finetuned-xquadv1](https://huggingface.co/mrm8488/bert-multi-uncased-finetuned-xquadv1)\n",
        "\n",
        "## A fined tuned version of BERT base **multilingual** uncased on [XQUAD](https://github.com/deepmind/xquad/blob/master/README.md) dataset (```multilingual Q&A```)\n",
        "\n",
        "Supported Languages (11):\n",
        "```\n",
        "- Arabic: `ar`\n",
        "- German: `de`\n",
        "- Greek: `el`\n",
        "- English: `en`\n",
        "- Spanish: `es`\n",
        "- Hindi: `hi`\n",
        "- Russian: `ru`\n",
        "- Thai: `th`\n",
        "- Turkish: `tr`\n",
        "- Vietnamese: `vi`\n",
        "- Chinese: `zh`\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70UYUF6Ob7vI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "99a9403b-acf7-45f0-db50-63609c6b5c02"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 501kB 4.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 870kB 23.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 38.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 51.9MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCoInXk-cFTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "qa_pipeline = pipeline(\n",
        "    \"question-answering\",\n",
        "    model=\"mrm8488/bert-multi-uncased-finetuned-xquadv1\",\n",
        "    tokenizer=\"mrm8488/bert-multi-uncased-finetuned-xquadv1\"\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyObybtDcbF0",
        "colab_type": "text"
      },
      "source": [
        "### Spanish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zBho6MOccb-",
        "colab_type": "code",
        "outputId": "2e82b1a5-4379-4fc5-ff89-ea70f3e654f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Manuel Romero ha estado colaborando activamente últimamente en el repositorio de hugginface/transformers\",\n",
        "    'question': \"¿Quién ha estado colaborando de forma activa en hugginface/transformers?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 190.70it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6069.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Manuel Romero', 'end': 13, 'score': 0.6817649967337047, 'start': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyRFfgFRch4H",
        "colab_type": "text"
      },
      "source": [
        "### English"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IVtxQNB1ceiv",
        "colab_type": "code",
        "outputId": "9e495259-8ab6-4dbc-db1d-92e3760c6c73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Manuel Romero has been working hardly in the repository hugginface/transformers lately\",\n",
        "    'question': \"Who has been working hard for hugginface/transformers lately?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 183.84it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6482.70it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Manuel Romero', 'end': 13, 'score': 0.715519859329504, 'start': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMj7oF5Dcmbu",
        "colab_type": "text"
      },
      "source": [
        "### German"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbgyuzsNclEF",
        "colab_type": "code",
        "outputId": "fb9a18cb-19f8-4e38-d67c-8b721896519f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Manuel Romero hat in letzter Zeit kaum im Hugginface / Transformers-Repository gearbeitet\",\n",
        "    'question': \"Für welches Repository hat Manuel Romero in letzter Zeit gearbeitet?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 247.61it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7025.63it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Hugginface / Transformers-Repository',\n",
              " 'end': 78,\n",
              " 'score': 0.5922690127954304,\n",
              " 'start': 42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3veaGBmJcunH",
        "colab_type": "text"
      },
      "source": [
        "### French"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHJVI7KQctcl",
        "colab_type": "code",
        "outputId": "f1e1415e-767f-407c-e46e-74ac0a70f84c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Manuel Romero a travaillé à peine dans le référentiel hugginface / transformers ces derniers temps\",\n",
        "    'question': \"Pour quel référentiel a travaillé Manuel Romero récemment?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 184.61it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 1733.90it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'hugginface / transformers',\n",
              " 'end': 79,\n",
              " 'score': 0.6488578824417459,\n",
              " 'start': 54}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8sNsjNtc3Il",
        "colab_type": "text"
      },
      "source": [
        "### Russian"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVn_8yhdc1jb",
        "colab_type": "code",
        "outputId": "ebb9ca2b-d077-4233-86e6-4bbd17fd6860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "qa_pipeline({\n",
        "    'context': \"Мануэль Ромеро в последнее время почти не работал в репозитории hugginface / transformers\",\n",
        "    'question': \"Кто в последнее время усердно работал над обнимашками / трансформерами?\"\n",
        "    \n",
        "})"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 239.94it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 411.17it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Мануэль Ромеро',\n",
              " 'end': 14,\n",
              " 'score': 0.6974524093281502,\n",
              " 'start': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz6FS8nAc-Dv",
        "colab_type": "text"
      },
      "source": [
        "### Hindi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd84mWGcc8cU",
        "colab_type": "code",
        "outputId": "5a272b5a-db1a-4912-b06d-699a4fc2ff68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# context: Coronavirus is seeding panic in the West because it expands so fast.\n",
        "# question: Where is seeding panic Coronavirus?\n",
        "qa_pipeline({\n",
        "    'context': \"कोरोनावायरस पश्चिम में आतंक बो रहा है क्योंकि यह इतनी तेजी से फैलता है।\",\n",
        "    'question': \"कोरोनावायरस घबराहट कहां है?\"\n",
        "    \n",
        "})\n",
        "# output: West"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 165.49it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 3563.55it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'पश्चिम में आतंक',\n",
              " 'end': 27,\n",
              " 'score': 0.04333575414534829,\n",
              " 'start': 12}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cui4YwhudD0n",
        "colab_type": "text"
      },
      "source": [
        "### Chinese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpLzs_NHdCzD",
        "colab_type": "code",
        "outputId": "752dbba9-7444-4ddc-88c3-d4ab178dbf22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "# context: coronavirus is seeding the confusion in Europe because it spreads so fast. A lot of public events are being suspended.\n",
        "# question: Where does coronavirus cause confusion?\n",
        "qa_pipeline({\n",
        "    'context': \"冠状病毒在欧洲引起了混乱，因为它的传播速度如此之快。 许多公共活动都被暂停。\",\n",
        "    'question': \"冠状病毒在哪里引起混乱？\"\n",
        "    \n",
        "})\n",
        "# output: Coronavirus has caused confusion in Europe because it spreads so fast."
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 212.64it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 6393.76it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': '冠状病毒在欧洲引起了混乱，因为它的传播速度如此之快。',\n",
              " 'end': 26,\n",
              " 'score': 0.7257830859596304,\n",
              " 'start': 0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-c8u9XxOe5UU",
        "colab_type": "text"
      },
      "source": [
        "## Bonus: do it in a FORM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGA6yPiFe-JW",
        "colab_type": "code",
        "outputId": "efe19499-7337-4da1-8b8c-4bf39a9612bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "#@title Q&A Form\n",
        "\n",
        "context = 'Վերջերս Մանուել Ռոմերոն ակտիվորեն համագործակցում է hugginface / transformers պահոցում' #@param {type:\"string\"}\n",
        "question = 'Ո՞վ է ակտիվորեն համագործակցում hugginface / տրանսֆորմատորներում' #@param {type:\"string\"}\n",
        "\n",
        "qa_pipeline({\n",
        "    'context': context,\n",
        "    'question': question\n",
        "    \n",
        "})"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert squad examples to features: 100%|██████████| 1/1 [00:00<00:00, 169.06it/s]\n",
            "add example index and unique id: 100%|██████████| 1/1 [00:00<00:00, 7516.67it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'Մանուել Ռոմերոն',\n",
              " 'end': 23,\n",
              " 'score': 0.6901003019312313,\n",
              " 'start': 8}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFvmXLP1fHsS",
        "colab_type": "text"
      },
      "source": [
        "> Created by [Manuel Romero/@mrm8488](https://twitter.com/mrm8488)"
      ]
    }
  ]
}